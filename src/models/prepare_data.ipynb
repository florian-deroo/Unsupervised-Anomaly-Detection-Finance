{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:58:58.250755Z",
     "start_time": "2025-02-23T02:58:57.266248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.types import dsf_dtype_dict\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bokeh.plotting import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "from dask.distributed import LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()"
   ],
   "id": "9581623b6baecc3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b89cb1bf2fb6ca90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:30:04.206683Z",
     "start_time": "2025-02-23T02:30:04.203159Z"
    }
   },
   "source": [
    "price_columns = ['DlyClose', 'DlyLow', 'DlyHigh', 'DlyBid', 'DlyAsk']\n",
    "columns_to_keep = price_columns + [\"PERMNO\", \"DlyCalDt\", \"DlyVol\"]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-14T03:40:50.980339Z",
     "start_time": "2025-02-14T03:40:50.303698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dd.read_csv(\"../../data/dsf_v2_patched.csv/*.part\",\n",
    "                   dtype=dsf_dtype_dict,\n",
    "                   parse_dates=['DlyCalDt'],\n",
    "                   usecols=columns_to_keep\n",
    "                   )"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def norm(df_input, window=50):\n",
    "    df = df_input[[\"PERMNO\", \"DlyCalDt\", \"DlyVol\", \"DlyClose\"]].copy()\n",
    "    group = df_input.groupby('PERMNO')\n",
    "    df['Close'] = df['DlyClose']\n",
    "\n",
    "    # Volume normalization with metadata\n",
    "    df['DlyVol'] = group['DlyVol'].transform(\n",
    "        lambda x: (np.log1p(x) - np.log1p(x).rolling(window=window, center=False).mean()) /\n",
    "                  (np.log1p(x).rolling(window=window, center=False).std() + 1e-8),\n",
    "        meta=('DlyVol', 'float64')\n",
    "    )\n",
    "\n",
    "    df['DlyVol'] = (df['DlyVol'] + 3) / 6\n",
    "\n",
    "    # For log-returns\n",
    "    for col in price_columns:\n",
    "        # Calculate log returns directly into the dataframe\n",
    "        df[col] = group[col].transform(\n",
    "            lambda x: np.log(x / x.shift(1)),\n",
    "            meta=(col, 'float64')\n",
    "        )\n",
    "\n",
    "        # Z-score normalization with rolling window\n",
    "        df[f'{col}'] = group[col].transform(\n",
    "            lambda x: (x - x.rolling(window=window, center=False).mean()) /\n",
    "                      (x.rolling(window=window, center=False).std() + 1e-8),\n",
    "            meta=(f'{col}', 'float64')\n",
    "        )\n",
    "\n",
    "        # Clip extreme values\n",
    "        df[f'{col}'] = df[f'{col}'].clip(-3, 3)\n",
    "\n",
    "        # Normalize to [0,1]\n",
    "        df[f'{col}'] = (df[f'{col}'] + 3) / 6\n",
    "\n",
    "    df.to_csv(\"./dsf_normalized_3_with_norm_data.csv\")\n",
    "\n",
    "norm(data, window=50)"
   ],
   "id": "c30b00d2da32b275",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:00:40.003397Z",
     "start_time": "2025-02-13T17:00:39.684832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dd.read_csv(\"./dsf_normalized_3_with_norm_data.csv/*.part\",\n",
    "                   dtype=dsf_dtype_dict,\n",
    "                   parse_dates=['DlyCalDt'],\n",
    "                   )"
   ],
   "id": "94a34e3a0a16a92c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T17:42:50.304348Z",
     "start_time": "2025-02-13T17:26:39.039785Z"
    }
   },
   "cell_type": "code",
   "source": "data.to_csv(\"./dsf_normalized_3_with_norm_single.csv\", single_file=True)",
   "id": "d0f0d7846717b3df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\Work\\\\Projet Finance\\\\SynologyDrive\\\\src\\\\sentiment\\\\dsf_normalized_3_with_norm_single.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:47:06.609930Z",
     "start_time": "2025-02-23T02:30:11.703626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"./dsf_normalized_3_with_norm_single.csv\",\n",
    "                   dtype=dsf_dtype_dict,\n",
    "                   parse_dates=['DlyCalDt'],\n",
    "                   usecols=[\"PERMNO\", \"DlyCalDt\", \"DlyClose\", \"DlyLow\", \"DlyHigh\", \"DlyBid\", \"DlyAsk\", \"DlyVol\",\n",
    "                            \"Close\"],\n",
    "                   )"
   ],
   "id": "159f0d39f20158df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T02:47:28.215228Z",
     "start_time": "2025-02-23T02:47:28.129005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_size = 50\n",
    "\n",
    "def is_window_valid(window_data, nan_counts):\n",
    "    return not any(nan_counts[start:start + window_size].any() for start in range(len(window_data) - window_size + 1))\n",
    "\n",
    "def find_valid_windows(df):\n",
    "    if len(df) < window_size:\n",
    "        return []\n",
    "\n",
    "    nan_mask = df[price_columns + ['DlyVol']].isna()\n",
    "\n",
    "    close_prices = df['Close'].to_numpy()\n",
    "    df_len = len(df)\n",
    "\n",
    "    future_max = np.full(df_len, np.nan)\n",
    "    valid_range = slice(window_size + 15, window_size + 25)\n",
    "\n",
    "    for i in range(df_len - window_size - 15):\n",
    "        future_slice = close_prices[i + valid_range.start:i + valid_range.stop]\n",
    "        if len(future_slice) > 0:\n",
    "            future_max[i] = np.max(future_slice)\n",
    "\n",
    "    price_increases = future_max < close_prices\n",
    "    potential_starts = np.where(price_increases)[0]\n",
    "\n",
    "    valid_indices = []\n",
    "    i = 0\n",
    "    while i < len(potential_starts):\n",
    "        start_idx = potential_starts[i]\n",
    "        if start_idx > df_len - window_size:\n",
    "            break\n",
    "\n",
    "        window_data = df.iloc[start_idx:start_idx + window_size]\n",
    "        if not nan_mask.iloc[start_idx:start_idx + window_size].values.any():\n",
    "            valid_indices.append(df.index[start_idx])\n",
    "            i = np.searchsorted(potential_starts, start_idx + window_size - 1, side='right')\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return valid_indices\n",
    "\n",
    "\n",
    "def build_df(df_input):\n",
    "    permnos = df_input['PERMNO'].unique()\n",
    "    estimated_size = len(df_input) // window_size\n",
    "    results = [None] * estimated_size\n",
    "    result_idx = 0\n",
    "\n",
    "    grouped = df_input.groupby('PERMNO')\n",
    "\n",
    "    for permno in tqdm(permnos, desc=\"Traitement des PERMNO\"):\n",
    "        group_df = grouped.get_group(permno)\n",
    "        valid_indices = find_valid_windows(group_df)\n",
    "\n",
    "        if valid_indices:\n",
    "            valid_starts = group_df.index.get_indexer(valid_indices)\n",
    "            group_array = group_df.to_numpy()\n",
    "\n",
    "            for start_idx in valid_starts:\n",
    "                if result_idx >= len(results):\n",
    "                    results.extend([None] * (estimated_size // 2))\n",
    "                results[result_idx] = pd.DataFrame(\n",
    "                    group_array[start_idx:start_idx + window_size],\n",
    "                    index=group_df.index[start_idx:start_idx + window_size],\n",
    "                    columns=group_df.columns\n",
    "                )\n",
    "                result_idx += 1\n",
    "\n",
    "    # Cr√©er le DataFrame final\n",
    "    final_df = pd.concat(results[:result_idx], axis=0)\n",
    "    final_df['window_id'] = np.arange(len(final_df)) // window_size + 1\n",
    "    final_df = final_df.drop([\"Close\"], axis=1)\n",
    "    final_df.to_csv(\"./final_stocks_negative.csv\", index=False)"
   ],
   "id": "b7aac2fba4c6640b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "build_df(data)",
   "id": "9d89080a095ca01c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
