{
 "cells": [
  {
   "cell_type": "code",
   "id": "b2eeab3e20fbd8d0",
   "metadata": {},
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NetworkConfig:\n",
    "    def __init__(\n",
    "            self,\n",
    "            base_channels,\n",
    "            compression_channels,\n",
    "            progression,\n",
    "            n_blocks\n",
    "    ):\n",
    "        self.seq_length = 50\n",
    "        self.input_channels = 6\n",
    "        self.base_channels = base_channels\n",
    "        self.compression_channels = compression_channels\n",
    "        self.n_blocks = n_blocks\n",
    "        self.progression = progression\n",
    "\n",
    "\n",
    "class DilatedBase(nn.Module):\n",
    "    def __init__(self, config: NetworkConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def _create_conv_block(\n",
    "            self,\n",
    "            dilation: int,\n",
    "            in_channels: int,\n",
    "            dilated_channels: int,\n",
    "            out_channels: int\n",
    "    ) -> nn.Sequential:\n",
    "        return nn.Sequential(\n",
    "            # Convolution dilatée\n",
    "            nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=dilated_channels,\n",
    "                kernel_size=3,\n",
    "                dilation=dilation,\n",
    "                padding='same'\n",
    "            ),\n",
    "            nn.BatchNorm1d(dilated_channels),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Compression/Expansion\n",
    "            nn.Conv1d(\n",
    "                in_channels=dilated_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "class DilatedEncoder(DilatedBase):\n",
    "    def __init__(self, config: NetworkConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        # Création des blocs dilatation + compression\n",
    "        self.conv_blocks = self._create_encoder_blocks()\n",
    "\n",
    "        # Couches de traitement final\n",
    "        self.pooling = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.final_projection = self._create_final_projection()\n",
    "        self.output_layers = self._create_output_layers()\n",
    "\n",
    "    def _create_encoder_blocks(self) -> nn.ModuleList:\n",
    "        \"\"\"Crée les blocs de convolution dilatée + compression.\"\"\"\n",
    "        modules = []\n",
    "        for i in range(self.config.n_blocks):\n",
    "            in_channels = self.config.input_channels if i == 0 else self.config.compression_channels\n",
    "            modules.append(\n",
    "                self._create_conv_block(\n",
    "                    dilation=2 ** (i + 1),\n",
    "                    in_channels=in_channels,\n",
    "                    dilated_channels=self.config.base_channels,\n",
    "                    out_channels=self.config.compression_channels\n",
    "                )\n",
    "            )\n",
    "        return nn.ModuleList(modules)\n",
    "\n",
    "    def _create_final_projection(self) -> nn.Sequential:\n",
    "        \"\"\"Crée la couche de projection finale.\"\"\"\n",
    "        concat_channels = self.config.compression_channels * self.config.n_blocks\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=concat_channels,\n",
    "                out_channels=self.config.compression_channels,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.BatchNorm1d(self.config.compression_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _create_output_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Crée les couches de sortie.\"\"\"\n",
    "        modules = []\n",
    "        in_channels = self.config.compression_channels\n",
    "\n",
    "        for out_channels in self.config.progression:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=3,\n",
    "                        padding='same'\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "        return nn.ModuleList(modules)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Debug des distributions\n",
    "        compressed_features = []\n",
    "        x_prev = x\n",
    "\n",
    "        for i, block in enumerate(self.conv_blocks):\n",
    "            x_compressed = block(x_prev)\n",
    "            x_prev = x_compressed\n",
    "            compressed_features.append(x_compressed)\n",
    "\n",
    "        concat = torch.cat(compressed_features, dim=1)\n",
    "\n",
    "        encoded = self.final_projection(concat)\n",
    "\n",
    "        for i, layer in enumerate(self.output_layers):\n",
    "            encoded = self.pooling(encoded)\n",
    "            encoded = layer(encoded)\n",
    "\n",
    "        return encoded\n",
    "\n",
    "\n",
    "class DilatedDecoder(DilatedBase):\n",
    "    def __init__(self, config: NetworkConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.input_layers = self._create_input_layers()\n",
    "        self.conv_blocks = self._create_decoder_blocks()\n",
    "        self.final_layer = self._create_final_projection()\n",
    "\n",
    "    def _create_decoder_blocks(self) -> nn.ModuleList:\n",
    "        \"\"\"Crée les blocs de convolution dilatée + expansion.\"\"\"\n",
    "        modules = []\n",
    "        for i in reversed(range(self.config.n_blocks)):\n",
    "            modules.append(\n",
    "                self._create_conv_block(\n",
    "                    dilation=2 ** (i + 1),\n",
    "                    in_channels=self.config.compression_channels,\n",
    "                    dilated_channels=self.config.base_channels,\n",
    "                    out_channels=self.config.compression_channels\n",
    "                )\n",
    "            )\n",
    "        return nn.ModuleList(modules)\n",
    "\n",
    "    def _create_input_layers(self) -> nn.ModuleList:\n",
    "        \"\"\"Crée les couches d'entrée avec upsampling.\"\"\"\n",
    "        modules = []\n",
    "        progression = list(reversed(self.config.progression))\n",
    "        prev_channels = progression[0]\n",
    "\n",
    "        for i, channels in enumerate(progression[1:] + [self.config.compression_channels]):\n",
    "            is_last_layer = i == len(progression[1:] + [self.config.compression_channels]) - 1\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Upsample(size=self.config.seq_length if is_last_layer else None,\n",
    "                                scale_factor=None if is_last_layer else 2),\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=prev_channels,\n",
    "                        out_channels=channels,\n",
    "                        kernel_size=3,\n",
    "                        padding='same'\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(channels),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            prev_channels = channels\n",
    "\n",
    "        return nn.ModuleList(modules)\n",
    "\n",
    "    def _create_final_projection(self) -> nn.Sequential:\n",
    "        \"\"\"Crée la couche de projection finale.\"\"\"\n",
    "        concat_channels = self.config.compression_channels * self.config.n_blocks\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=concat_channels,\n",
    "                out_channels=self.config.input_channels,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Application des couches d'entrée avec upsampling\n",
    "        decoded = x\n",
    "        for layer in self.input_layers:\n",
    "            decoded = layer(decoded)\n",
    "\n",
    "        # Application des blocs avec récupération des features\n",
    "        x_prev = decoded\n",
    "        compressed_features = []\n",
    "\n",
    "        for block in self.conv_blocks:\n",
    "            x_compressed = block(x_prev)\n",
    "            x_prev = x_compressed\n",
    "            compressed_features.append(x_compressed)\n",
    "\n",
    "        # Concaténation et couche finale\n",
    "        concat = torch.cat(compressed_features, dim=1)\n",
    "        decoded = self.final_layer(concat)\n",
    "\n",
    "        return decoded\n",
    "    \n",
    "class CompletModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.encoder = DilatedEncoder(config)\n",
    "        self.decoder = DilatedDecoder(config)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        output = self.decoder(encoded)\n",
    "        return output"
   ],
   "id": "f9b9de2b152f2545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# All windows\n",
    "\n",
    "data = pd.read_csv(\"./final_stocks_2.csv\", usecols=[\"log_return_DlyClose\", \"log_return_DlyLow\", \"log_return_DlyHigh\", \"log_return_DlyBid\", \"log_return_DlyAsk\", \"volume_normalized\"])"
   ],
   "id": "e1e7d4af4911bee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Positive Future windows\n",
    "\n",
    "data = pd.read_csv(\"./final_stocks_4.csv\", usecols=[\"DlyClose\", \"DlyLow\", \"DlyHigh\", \"DlyBid\", \"DlyAsk\", \"DlyVol\"])"
   ],
   "id": "2fca87d8affd4a9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Negative Future windows\n",
    "\n",
    "data = pd.read_csv(\"./final_stocks_negative.csv\", usecols=[\"DlyClose\", \"DlyLow\", \"DlyHigh\", \"DlyBid\", \"DlyAsk\", \"DlyVol\"])"
   ],
   "id": "c7fa7449ee842223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "seq_length = 50",
   "id": "1bd7d9fe646b5c17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stride = seq_length\n",
    "windows = np.array([data[i:i + seq_length] for i in range(0, len(data) - seq_length - 1, stride)])\n",
    "windows = torch.FloatTensor(windows).transpose(1, 2)\n",
    "train_size = int(0.9 * len(windows))\n",
    "val_size = len(windows) - train_size\n",
    "train_data, test_data = random_split(windows, [train_size, val_size])\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ],
   "id": "8da9b3807ab045f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "input_dim = 6\n",
    "\n",
    "learning_rate = 0.001\n",
    "base_channels = 20\n",
    "compression_channels = 6\n",
    "n_blocks = 5\n",
    "progression = [20, 40, 60]\n",
    "\n",
    "model_folder = \"models/autoencoder_negative/\"\n",
    "\n",
    "config = NetworkConfig(\n",
    "    n_blocks=n_blocks,\n",
    "    base_channels=base_channels,\n",
    "    compression_channels=compression_channels,\n",
    "    progression=progression\n",
    ")\n",
    "\n",
    "model = CompletModel(config).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "id": "d9b0b15ffee9df54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timer = time.time()\n",
    "folder = model_folder + str(timer) + \"/\"\n",
    "os.makedirs(folder + \"checkpoints/\", exist_ok=True)\n",
    "\n",
    "# Sauvegarde de la configuration\n",
    "config = {\n",
    "    # Paramètres d'entraînement\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': learning_rate,\n",
    "    'device': str(device),\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    'input_dim': input_dim,\n",
    "    'seq_len': seq_length,\n",
    "    'base_channels': base_channels,\n",
    "    'compression_channels': compression_channels,\n",
    "    'progression': progression,\n",
    "    \n",
    "    # Informations sur l'architecture\n",
    "    'optimizer': optimizer.__class__.__name__,\n",
    "    \n",
    "    # Timestamp et dossier\n",
    "    'timestamp': timer,\n",
    "    'model_folder': model_folder\n",
    "}\n",
    "\n",
    "# Sauvegarde de la configuration\n",
    "with open(folder + 'config.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(config, f, ensure_ascii=False, indent=4)"
   ],
   "id": "80966d3aa2198bb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils.train import train_model\n",
    "\n",
    "train_model(model, 100, train_loader, test_loader, optimizer, device, folder)"
   ],
   "id": "f36ca52f707b0ca4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "timestamp = \"1740724678.7526445\"\n",
    "path_checkpoint = model_folder + timestamp + \"/checkpoints/model_epoch_7.pt\""
   ],
   "id": "9028c0010f480a64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(path_checkpoint)\n",
    "model.load_state_dict(checkpoint['transformer_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()"
   ],
   "id": "7e02ea379279be0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.types import dsf_dtype_dict\n",
    "\n",
    "dsf = pd.read_csv(\"./dsf_v2_patched_small.csv\",\n",
    "                  dtype=dsf_dtype_dict,\n",
    "                  parse_dates=['DlyCalDt'],\n",
    "                  usecols=['DlyCalDt', 'PERMNO', 'DlyClose']\n",
    "                  )"
   ],
   "id": "608ca3a25b6af88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ALL WINDOWS\n",
    "final_stocks = pd.read_csv(\"./final_stocks_2.csv\")"
   ],
   "id": "245a23609fd77071",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.benchmark.benchmark import build_predictions\n",
    "\n",
    "predictions_results = build_predictions(model, final_stocks, device, model_folder + timestamp + \"/\")"
   ],
   "id": "5a90e438623ec8ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions_results = pd.read_csv(folder + \"predictions_results.csv\")",
   "id": "ae96a3d03ffb4c2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.benchmark.benchmark import build_quantiles\n",
    "\n",
    "quantiles = [0.98, 0.99, 0.994, 0.995, 0.996, 0.997]\n",
    "quantiles_results = build_quantiles(predictions_results, quantiles, dsf)"
   ],
   "id": "1b46a397160da830",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.benchmark.benchmark import analyze_quantiles\n",
    "\n",
    "analyze_quantiles(quantiles_results, model_folder + timestamp + \"/stats\", False)\n",
    "analyze_quantiles(quantiles_results, model_folder + timestamp + \"/stats\", True)"
   ],
   "id": "782524419deb4ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "855b1ddd384fc2f5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
